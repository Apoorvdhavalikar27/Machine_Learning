{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .........First we compare hyperparameters for different models like svm,random forest etc......\n",
    "# 1.SVM\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167\n",
    "# Refer above link for SVM hyperparameters ☝\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris \n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data,columns = [iris.feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(iris.target,columns = ['flower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df,df1],axis= 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['flower'])\n",
    "y = data.flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split,cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(gamma= 'auto',C = 30 ,kernel='rbf')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(gamma= 'auto',C = 10 ,kernel='rbf'),X,y,cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(gamma= 'auto',C = 20 ,kernel='rbf'),X,y,cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.9       , 0.93333333, 1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(gamma= 'auto',C = 30 ,kernel='rbf'),X,y,cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kernal : rbf ,C : 1,score 0.9800000000000001 \n",
      " kernal : rbf ,C : 10,score 0.9800000000000001 \n",
      " kernal : rbf ,C : 20,score 0.9666666666666668 \n",
      " kernal : linear ,C : 1,score 0.9800000000000001 \n",
      " kernal : linear ,C : 10,score 0.9733333333333334 \n",
      " kernal : linear ,C : 20,score 0.9666666666666666 \n"
     ]
    }
   ],
   "source": [
    "# To compare the hyperparameters in classifier we can write this hard code\n",
    "import numpy as np\n",
    "kernels = ['rbf','linear']\n",
    "c  = [1,10,20]\n",
    "for kval in kernels:\n",
    "    for cval in c:\n",
    "        score = cross_val_score(SVC(gamma= 'auto',C = cval ,kernel = kval),X,y,cv = 5)\n",
    "        avg_score = print(' kernal : {} ,C : {},score {} '.format(kval , str(cval),np.average(score)))\n",
    "avg_score       \n",
    "# avg_score gives avg accuracy when we use respective kernel and C value\n",
    "# from following result (rbf,1); (rbf,10); (linear,1) this combinations having more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00240769, 0.00118723, 0.00139594, 0.00100441, 0.0009973 ,\n",
       "        0.0015965 ]),\n",
       " 'std_fit_time': array([1.01767048e-03, 4.04373812e-04, 4.91566220e-04, 1.93206744e-05,\n",
       "        6.88365266e-06, 5.00075417e-04]),\n",
       " 'mean_score_time': array([0.00135832, 0.00101357, 0.00080733, 0.00099931, 0.00100894,\n",
       "        0.00080099]),\n",
       " 'std_score_time': array([4.91771328e-04, 1.33849473e-05, 4.03670224e-04, 1.77692073e-05,\n",
       "        9.23194175e-06, 4.00523730e-04]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10, 20, 20],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 20, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'kernel': 'linear'}],\n",
       " 'split0_test_score': array([0.96666667, 0.96666667, 0.96666667, 1.        , 0.96666667,\n",
       "        1.        ]),\n",
       " 'split1_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.9       , 0.9       ,\n",
       "        0.9       ]),\n",
       " 'split3_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "        0.93333333]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.98      , 0.98      , 0.98      , 0.97333333, 0.96666667,\n",
       "        0.96666667]),\n",
       " 'std_test_score': array([0.01632993, 0.01632993, 0.01632993, 0.03887301, 0.03651484,\n",
       "        0.0421637 ]),\n",
       " 'rank_test_score': array([1, 1, 1, 4, 5, 6])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for alternate to this hard code sklearn has one search method calles GridSearchCV(model,param_grid,cv)\n",
    "clf = GridSearchCV(SVC(gamma='auto'),{'C':[1,10,20],'kernel':['rbf','linear']},cv = 5,return_train_score=False)\n",
    "clf.fit(X,y)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 20, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.036515</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 20, 'kernel': 'linear'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.042164</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.002408      0.001018         0.001358        0.000492       1   \n",
       "1       0.001187      0.000404         0.001014        0.000013       1   \n",
       "2       0.001396      0.000492         0.000807        0.000404      10   \n",
       "3       0.001004      0.000019         0.000999        0.000018      10   \n",
       "4       0.000997      0.000007         0.001009        0.000009      20   \n",
       "5       0.001596      0.000500         0.000801        0.000401      20   \n",
       "\n",
       "  param_kernel                         params  split0_test_score  \\\n",
       "0          rbf      {'C': 1, 'kernel': 'rbf'}           0.966667   \n",
       "1       linear   {'C': 1, 'kernel': 'linear'}           0.966667   \n",
       "2          rbf     {'C': 10, 'kernel': 'rbf'}           0.966667   \n",
       "3       linear  {'C': 10, 'kernel': 'linear'}           1.000000   \n",
       "4          rbf     {'C': 20, 'kernel': 'rbf'}           0.966667   \n",
       "5       linear  {'C': 20, 'kernel': 'linear'}           1.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                1.0           0.966667           0.966667                1.0   \n",
       "1                1.0           0.966667           0.966667                1.0   \n",
       "2                1.0           0.966667           0.966667                1.0   \n",
       "3                1.0           0.900000           0.966667                1.0   \n",
       "4                1.0           0.900000           0.966667                1.0   \n",
       "5                1.0           0.900000           0.933333                1.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.980000        0.016330                1  \n",
       "1         0.980000        0.016330                1  \n",
       "2         0.980000        0.016330                1  \n",
       "3         0.973333        0.038873                4  \n",
       "4         0.966667        0.036515                5  \n",
       "5         0.966667        0.042164                6  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we convert this messy data into dataframe\n",
    "hypm_svm = pd.DataFrame(clf.cv_results_)\n",
    "hypm_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for estimator 1 is 0.9333333333333333\n",
      "Accuracy for estimator 10 is 0.9333333333333333\n",
      "Accuracy for estimator 15 is 0.9333333333333333\n",
      "Accuracy for estimator 20 is 0.9333333333333333\n",
      "Accuracy for estimator 30 is 0.9333333333333333\n",
      "Accuracy for estimator 40 is 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# .........Random Forest.......\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "# Refer above link for hyperparameters ☝\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# first lets write hard code\n",
    " \n",
    "estimator = [1,10,15,20,30,40]\n",
    "for estval in estimator:\n",
    "    clf = RandomForestClassifier(n_estimators = estval)\n",
    "    clf.fit(X_train,y_train)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    print('Accuracy for estimator {} is {}'.format(estval,score))\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00319991, 0.0105011 , 0.01354074, 0.01659031, 0.02341242,\n",
       "        0.03179507]),\n",
       " 'std_fit_time': array([0.001166  , 0.00210784, 0.0012632 , 0.00136128, 0.00139961,\n",
       "        0.00072563]),\n",
       " 'mean_score_time': array([0.00179987, 0.00220809, 0.00200777, 0.00261369, 0.00301127,\n",
       "        0.00321255]),\n",
       " 'std_score_time': array([7.47831202e-04, 4.17491576e-04, 6.41947599e-04, 5.00544816e-04,\n",
       "        1.61149797e-05, 4.18270281e-04]),\n",
       " 'param_n_estimators': masked_array(data=[1, 10, 15, 20, 30, 40],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 1},\n",
       "  {'n_estimators': 10},\n",
       "  {'n_estimators': 15},\n",
       "  {'n_estimators': 20},\n",
       "  {'n_estimators': 30},\n",
       "  {'n_estimators': 40}],\n",
       " 'split0_test_score': array([0.95833333, 0.95833333, 0.95833333, 0.95833333, 0.95833333,\n",
       "        0.95833333]),\n",
       " 'split1_test_score': array([0.75      , 0.95833333, 1.        , 0.95833333, 0.95833333,\n",
       "        0.95833333]),\n",
       " 'split2_test_score': array([0.875     , 0.875     , 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667]),\n",
       " 'split3_test_score': array([1.        , 0.95833333, 0.95833333, 0.95833333, 0.95833333,\n",
       "        0.95833333]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.91666667, 0.95      , 0.96666667, 0.95833333, 0.95833333,\n",
       "        0.95833333]),\n",
       " 'std_test_score': array([0.09501462, 0.04082483, 0.03118048, 0.02635231, 0.02635231,\n",
       "        0.02635231]),\n",
       " 'rank_test_score': array([6, 5, 1, 2, 2, 2])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now using GridSearchCV\n",
    "clf1 = GridSearchCV(RandomForestClassifier(),{'n_estimators':[1,10,15,20,30,40]},cv = 5,return_train_score=False)\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.040825</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013541</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_estimators': 15}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016590</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.026352</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023412</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.026352</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031795</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>40</td>\n",
       "      <td>{'n_estimators': 40}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.026352</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.003200      0.001166         0.001800        0.000748   \n",
       "1       0.010501      0.002108         0.002208        0.000417   \n",
       "2       0.013541      0.001263         0.002008        0.000642   \n",
       "3       0.016590      0.001361         0.002614        0.000501   \n",
       "4       0.023412      0.001400         0.003011        0.000016   \n",
       "5       0.031795      0.000726         0.003213        0.000418   \n",
       "\n",
       "  param_n_estimators                params  split0_test_score  \\\n",
       "0                  1   {'n_estimators': 1}           0.958333   \n",
       "1                 10  {'n_estimators': 10}           0.958333   \n",
       "2                 15  {'n_estimators': 15}           0.958333   \n",
       "3                 20  {'n_estimators': 20}           0.958333   \n",
       "4                 30  {'n_estimators': 30}           0.958333   \n",
       "5                 40  {'n_estimators': 40}           0.958333   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.750000           0.875000           1.000000                1.0   \n",
       "1           0.958333           0.875000           0.958333                1.0   \n",
       "2           1.000000           0.916667           0.958333                1.0   \n",
       "3           0.958333           0.916667           0.958333                1.0   \n",
       "4           0.958333           0.916667           0.958333                1.0   \n",
       "5           0.958333           0.916667           0.958333                1.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.916667        0.095015                6  \n",
       "1         0.950000        0.040825                5  \n",
       "2         0.966667        0.031180                1  \n",
       "3         0.958333        0.026352                2  \n",
       "4         0.958333        0.026352                2  \n",
       "5         0.958333        0.026352                2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypm_rf = pd.DataFrame(clf1.cv_results_)\n",
    "hypm_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 15}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00340881, 0.03328481, 0.01253719]),\n",
       " 'std_fit_time': array([0.00121175, 0.0015843 , 0.00071795]),\n",
       " 'mean_score_time': array([0.00159316, 0.00377698, 0.00260439]),\n",
       " 'std_score_time': array([0.00048435, 0.0011541 , 0.00049993]),\n",
       " 'param_n_estimators': masked_array(data=[1, 40, 15],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 1}, {'n_estimators': 40}, {'n_estimators': 15}],\n",
       " 'split0_test_score': array([0.95833333, 0.95833333, 0.95833333]),\n",
       " 'split1_test_score': array([0.95833333, 0.95833333, 0.95833333]),\n",
       " 'split2_test_score': array([1.        , 0.91666667, 0.91666667]),\n",
       " 'split3_test_score': array([0.91666667, 0.95833333, 0.95833333]),\n",
       " 'split4_test_score': array([1., 1., 1.]),\n",
       " 'mean_test_score': array([0.96666667, 0.95833333, 0.95833333]),\n",
       " 'std_test_score': array([0.03118048, 0.02635231, 0.02635231]),\n",
       " 'rank_test_score': array([1, 2, 2])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomized cv randomly iterate any combinations \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf2 = RandomizedSearchCV(RandomForestClassifier(),{'n_estimators':[1,10,15,20,30,40]},n_iter=3,cv = 5,return_train_score=False)\n",
    "clf2.fit(X_train,y_train)\n",
    "clf2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033285</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>40</td>\n",
       "      <td>{'n_estimators': 40}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.026352</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_estimators': 15}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.026352</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.003409      0.001212         0.001593        0.000484   \n",
       "1       0.033285      0.001584         0.003777        0.001154   \n",
       "2       0.012537      0.000718         0.002604        0.000500   \n",
       "\n",
       "  param_n_estimators                params  split0_test_score  \\\n",
       "0                  1   {'n_estimators': 1}           0.958333   \n",
       "1                 40  {'n_estimators': 40}           0.958333   \n",
       "2                 15  {'n_estimators': 15}           0.958333   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.958333           1.000000           0.916667                1.0   \n",
       "1           0.958333           0.916667           0.958333                1.0   \n",
       "2           0.958333           0.916667           0.958333                1.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.966667        0.031180                1  \n",
       "1         0.958333        0.026352                2  \n",
       "2         0.958333        0.026352                2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypm_rf2 = pd.DataFrame(clf2.cv_results_)\n",
    "hypm_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we compare diff classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm':{\n",
    "        'clf':SVC(gamma='auto'),\n",
    "        'param':{\n",
    "            'C':[1,5,10,15],\n",
    "            'kernel':['linear','rbf']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Logistic_regression':{\n",
    "        'clf':LogisticRegression(),\n",
    "        'param':{\n",
    "            'C':[1,5,10,15]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Random_forest':{\n",
    "        'clf':RandomForestClassifier(),\n",
    "        'param':{\n",
    "            'n_estimators':[1,5,10,15]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for model_name,mp in model_params.items():\n",
    "    model = GridSearchCV(mp['clf'],mp['param'],cv=5,return_train_score=False)\n",
    "    model.fit(X,y)\n",
    "    score.append({\n",
    "        'model':model_name,\n",
    "        'best_score':model.best_score_,\n",
    "        'best_param':model.best_params_\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic_regression</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>{'C': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                    best_param\n",
       "0                  svm    0.980000  {'C': 1, 'kernel': 'linear'}\n",
       "1  Logistic_regression    0.980000                     {'C': 10}\n",
       "2        Random_forest    0.966667           {'n_estimators': 5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(score)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'svm',\n",
       "  'best_score': 0.9800000000000001,\n",
       "  'best_param': {'C': 1, 'kernel': 'linear'}},\n",
       " {'model': 'Logistic_regression',\n",
       "  'best_score': 0.9800000000000001,\n",
       "  'best_param': {'C': 10}},\n",
       " {'model': 'Random_forest',\n",
       "  'best_score': 0.9666666666666668,\n",
       "  'best_param': {'n_estimators': 5}}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
